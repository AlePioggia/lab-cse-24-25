{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99b6b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:34:09.444324Z",
     "iopub.status.busy": "2022-02-28T15:34:09.441785Z",
     "iopub.status.idle": "2022-02-28T15:34:10.302913Z",
     "shell.execute_reply": "2022-02-28T15:34:10.302209Z",
     "shell.execute_reply.started": "2022-02-28T15:34:09.444282Z"
    }
   },
   "source": [
    "# 104 Spark - Movielens\n",
    "\n",
    "The goal of this lab is to run some analysis on a different dataset, [MovieLens](https://grouplens.org/datasets/movielens/).\n",
    "\n",
    "- [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "- [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "- [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)\n",
    "\n",
    "Download the dataset [here](https://big.csr.unibo.it/downloads/bigdata/ml-dataset.zip), unzip it and put it in the ```datasets/big``` folder.\n",
    "\n",
    "- ml-movies.csv (<u>movieId</u>:Long, title:String, genres:String) \n",
    "    - genres are separated by pipelines  (e.g., \"comedy|drama|action\")\n",
    "    - each movie is associated with many ratings\n",
    "\n",
    "- ml-ratings.csv (<u>userId</u>:Long, <u>movieId</u>:Long, rating:Double, year:Int)\n",
    "    - each rating is associated with many tags\n",
    "    - ml-ratings-sample.csv is a small sample of ml-ratings.csv, useful for developing\n",
    "- ml-tags.csv (<u>userId</u>:Long, <u>movieId</u>:Long, <u>tag</u>:String, year:Int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b673a91143a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6297e3f5-17d3-44ba-a06c-8b1acf0ca078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_to_datasets: String = ../../../../datasets/big/\r\n",
       "path_ml_movies: String = ../../../../datasets/big/ml-movies.csv\r\n",
       "path_ml_ratings: String = ../../../../datasets/big/ml-ratings-sample.csv\r\n",
       "path_ml_tags: String = ../../../../datasets/big/ml-tags.csv\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path_to_datasets = \"../../../../datasets/big/\"\n",
    "\n",
    "val path_ml_movies = path_to_datasets + \"ml-movies.csv\"\n",
    "val path_ml_ratings = path_to_datasets + \"ml-ratings-sample.csv\"\n",
    "val path_ml_tags = path_to_datasets + \"ml-tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e643e27d-b710-43cb-bc3d-7bca65e93b15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import java.util.Calendar\r\n",
       "import org.apache.spark.sql.SaveMode\r\n",
       "import org.apache.spark.HashPartitioner\r\n",
       "defined object MovieLensParser\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.util.Calendar\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "object MovieLensParser {\n",
    "\n",
    "  val noGenresListed = \"(no genres listed)\"\n",
    "  val commaRegex = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val pipeRegex = \"\\\\|(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val quotes = \"\\\"\"\n",
    "  \n",
    "  /** Convert from timestamp (String) to year (Int) */\n",
    "  def yearFromTimestamp(timestamp: String): Int = {\n",
    "    val cal = Calendar.getInstance()\n",
    "    cal.setTimeInMillis(timestamp.trim.toLong * 1000L)\n",
    "    cal.get(Calendar.YEAR)\n",
    "  }\n",
    "\n",
    "  /** Function to parse movie records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing movieId, title and genres, none in case of input errors\n",
    "   */\n",
    "  def parseMovieLine(line: String): Option[(Long, String, String)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      var title = input(1).trim\n",
    "      title = if(title.startsWith(quotes)) title.substring(1) else title\n",
    "      title = if(title.endsWith(quotes)) title.substring(0, title.length - 1) else title\n",
    "      Some(input(0).trim.toLong, title, input(2).trim)\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /** Function to parse rating records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing userId, movieId, rating, and year none in case of input errors\n",
    "   */\n",
    "  def parseRatingLine(line: String): Option[(Long, Long, Double, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim.toLong, input(1).trim.toLong, input(2).trim.toDouble, yearFromTimestamp(input(3)))\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /** Function to parse tag records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing userId, movieId, tag, and year, none in case of input errors\n",
    "   */\n",
    "  def parseTagLine(line: String) : Option[(Long, Long, String, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim.toLong, input(1).trim.toLong, input(2), yearFromTimestamp(input(3)))\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e69ae6f-50f6-4e2f-9fe8-ff6d747e675f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMovies: org.apache.spark.rdd.RDD[(Long, String, String)] = MapPartitionsRDD[2] at flatMap at <console>:36\r\n",
       "rddRatings: org.apache.spark.rdd.RDD[(Long, Long, Double, Int)] = MapPartitionsRDD[5] at flatMap at <console>:37\r\n",
       "rddTags: org.apache.spark.rdd.RDD[(Long, Long, String, Int)] = MapPartitionsRDD[8] at flatMap at <console>:38\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddMovies = sc.textFile(path_ml_movies).flatMap(MovieLensParser.parseMovieLine)\n",
    "val rddRatings = sc.textFile(path_ml_ratings).flatMap(MovieLensParser.parseRatingLine)\n",
    "val rddTags = sc.textFile(path_ml_tags).flatMap(MovieLensParser.parseTagLine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dfbdfd-2ee7-4488-a95f-9f1f809e581c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:59:00.715374Z",
     "iopub.status.busy": "2022-02-28T15:59:00.715148Z",
     "iopub.status.idle": "2022-02-28T15:59:01.005430Z",
     "shell.execute_reply": "2022-02-28T15:59:01.004685Z",
     "shell.execute_reply.started": "2022-02-28T15:59:00.715351Z"
    },
    "tags": []
   },
   "source": [
    "## 104-1 Datasets exploration\n",
    "\n",
    "Cache the dataset and answer the following questions:\n",
    "\n",
    "- How many (distinct) users, movies, ratings, and tags?\n",
    "- How many (distinct) genres?\n",
    "- On average, how many ratings per user?\n",
    "- On average, how many ratings per movie?\n",
    "- On average, how many genres per movie?\n",
    "- What is the range of ratings?\n",
    "- Which years? (print an ordered list)\n",
    "- On average, how many ratings per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f07a5b9-baaf-4564-8988-33e23ced42ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy)\n",
      "(1,307,3.5,2009)\n",
      "(14,110,epic,2015)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rddMoviesCached: rddMovies.type = MapPartitionsRDD[2] at flatMap at <console>:36\r\n",
       "rddRatingsCached: rddRatings.type = MapPartitionsRDD[5] at flatMap at <console>:37\r\n",
       "rddTagsCached: rddTags.type = MapPartitionsRDD[8] at flatMap at <console>:38\r\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddMoviesCached = rddMovies.cache()\n",
    "val rddRatingsCached = rddRatings.cache()\n",
    "val rddTagsCached = rddTags.cache()\n",
    "\n",
    "println(rddMoviesCached.first())\n",
    "println(rddRatingsCached.first())\n",
    "println(rddTagsCached.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1c29e6b-98d2-45d4-9387-b36f69de25b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "totalUsers: Long = 10073\r\n",
       "totalMovies: Long = 58098\r\n",
       "totalReviews: Long = 1000000\r\n",
       "totalTags: Long = 1108997\r\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// counting\n",
    "\n",
    "val totalUsers = rddRatingsCached.map(x => x._1).distinct().count()\n",
    "val totalMovies = rddMoviesCached.count()\n",
    "val totalReviews = rddRatingsCached.count()\n",
    "val totalTags = rddTagsCached.map(x => (x._1, x._2, x._3)).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19a4acca-fcc1-46ca-9bbf-59aee5db5931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "totalGenres: Array[String] = Array(War, Fantasy, Western, Musical, Horror, Crime, Animation, Thriller, Adventure, Action, IMAX, Children, Sci-Fi, Comedy, Documentary, Mystery, (no genres listed), Romance, Drama, Film-Noir)\r\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// distinct genres\n",
    "\n",
    "val totalGenres = rddMoviesCached.flatMap(x => x._3.split(\"\\\\|\")).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "764149e1-ebf1-44dc-9c11-9466c6dd5381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "groupings: org.apache.spark.rdd.RDD[(Long, Int)] = MapPartitionsRDD[330] at mapValues at <console>:43\r\n",
       "avgRatingsXUser: Double = 99.27529038022436\r\n",
       "userVoteCounts: org.apache.spark.rdd.RDD[(Long, Int)] = ShuffledRDD[334] at aggregateByKey at <console>:52\r\n",
       "totalVotes: Double = 1000000.0\r\n",
       "totalUsers: Long = 10073\r\n",
       "avgVotesPerUser: Double = 99.27529038022436\r\n"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// on average, how many ratings per user?\n",
    "\n",
    "// groupBy is inefficient, stores data in memeory before applying the transformation\n",
    "\n",
    "val groupings = rddRatingsCached\n",
    "    .map(x => (x._1, x._3))\n",
    "    .groupBy(_._1)\n",
    "    .mapValues(_.size)\n",
    "    .cache()\n",
    "\n",
    "val avgRatingsXUser = groupings.map(x => x._2).sum() / groupings.count()\n",
    "\n",
    "// aggregateBy solution\n",
    "\n",
    "val userVoteCounts = rddRatingsCached\n",
    "    .map(x => (x._1, 1))                // every evaluation counts as a vote\n",
    "    .aggregateByKey(0)(_ + _, _ + _)     // sums every value (not key), for every user\n",
    "\n",
    "val totalVotes = userVoteCounts.map(_._2).sum() \n",
    "val totalUsers = userVoteCounts.count()        \n",
    "\n",
    "// Calcola la media dei voti per utente\n",
    "val avgVotesPerUser = totalVotes / totalUsers.toDouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4af7a82f-dac1-48c8-845e-2c34057599dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratingsVoteCounts: org.apache.spark.rdd.RDD[(Long, Int)] = ShuffledRDD[349] at aggregateByKey at <console>:40\r\n",
       "totalVotes: Double = 1000000.0\r\n",
       "totalRatings: Long = 22031\r\n",
       "avgVotesPerMovie: Double = 45.39058599246516\r\n"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// On average, how many ratings per movie?\n",
    "// aggregateBy solution\n",
    "\n",
    "val ratingsVoteCounts = rddRatingsCached\n",
    "    .map(x => (x._2, 1))                // every evaluation counts as a vote\n",
    "    .aggregateByKey(0)(_ + _, _ + _)     // sums every value (not key), for every user\n",
    "\n",
    "val totalVotes = ratingsVoteCounts.map(_._2).sum() \n",
    "val totalRatings = ratingsVoteCounts.count()        \n",
    "\n",
    "// Calcola la media dei voti per utente\n",
    "val avgVotesPerMovie = totalVotes / totalRatings.toDouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "550335d5-2e66-4a62-aa4a-ad755086c47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genresPerMovie: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[367] at map at <console>:38\r\n",
       "avgGenres: Double = 1.8263451409687081\r\n",
       "res52: Array[Int] = Array(5, 3, 2, 3, 1, 3, 2, 2, 1, 3)\r\n"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// On average, how many genres per movie?\n",
    "\n",
    "val genresPerMovie = rddMoviesCached.map(x => x._3.split(\"\\\\|\").length).cache()\n",
    "\n",
    "val avgGenres = genresPerMovie.sum() / genresPerMovie.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "125889e2-c7f0-4177-8ddb-459b99316f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: 4.5 Min: 0.5 Max: 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ratings: org.apache.spark.rdd.RDD[Double] = MapPartitionsRDD[381] at distinct at <console>:39\r\n",
       "ratingsRange: Double = 4.5\r\n"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// What is the range of ratings?\n",
    "val ratings = rddRatingsCached.map(x => x._3).distinct().cache()\n",
    "val ratingsRange = ratings.max() - ratings.min()\n",
    "println(\"Range: \" + ratingsRange + \" Min: \" + ratings.min() + \" Max: \" + ratings.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "58462176-ce80-445f-acaf-15e899ab2be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "years: Array[Int] = Array(1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018)\r\n"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Which years? (print an ordered list)\n",
    "val years = rddRatingsCached.map(x => x._4).distinct().sortBy(x => x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "abafbb59-bf83-42a2-9afc-77c0afe0a138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[423] at map at <console>:35\r\n",
       "avgRatingsPerYear: Double = 43478.260869565216\r\n"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// on average how many ratings per year?\n",
    "\n",
    "val res = rddRatingsCached.map(x => (x._4, 1)).reduceByKey((x, y) => x + y).map(x => x._2).cache()\n",
    "val avgRatingsPerYear = res.sum() / res.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4016ac-cb34-48d0-a45c-29122e5fa59a",
   "metadata": {},
   "source": [
    "## 104-2 Compute the average rating for each movie\n",
    "\n",
    "- Export the result to a file\n",
    "- Do not start from cached RDDs\n",
    "- Evaluate:\n",
    "  - Join-and-Aggregate vs Aggregate-and-Join\n",
    "  - Best join vs broadcast\n",
    "- Use Power BI to check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "feb49547-58f9-4994-929a-da867e2e4cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_output_avgRatPerMovie: String = ../../../../output/avgRatPerMovie\r\n",
       "p: org.apache.spark.HashPartitioner = org.apache.spark.HashPartitioner@8\r\n",
       "rdd1: org.apache.spark.rdd.RDD[(Long, String)] = ShuffledRDD[622] at partitionBy at <console>:48\r\n",
       "rdd2: org.apache.spark.rdd.RDD[(Long, Double)] = ShuffledRDD[624] at partitionBy at <console>:49\r\n",
       "joined: org.apache.spark.rdd.RDD[(Long, (String, Double))] = MapPartitionsRDD[627] at join at <console>:53\r\n",
       "rdd3: org.apache.spark.rdd.RDD[(Long, String)] = ShuffledRDD[632] at partitionBy at <console>:61\r\n",
       "rdd4: org.apache.spark.rdd.RDD[(Long, Double)] = ShuffledRDD[636] at partitionBy at <console>:65\r\n",
       "res86: Array[(Long, (String, Double))] = Array((143464,(Where Hope Grows (2014),1.0)), (105040,(Dragon Day (2013),0.5)))\r\n"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path_output_avgRatPerMovie = \"../../../../output/avgRatPerMovie\"\n",
    "// rdd.coalesce(1).toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)\n",
    "\n",
    "sc.getPersistentRDDs.foreach(_._2.unpersist())\n",
    "val p = new HashPartitioner(8)\n",
    "\n",
    "// 1. Join and aggregate approach\n",
    "\n",
    "val rdd1 = rddMovies.map(x => (x._1, x._2)).partitionBy(p)\n",
    "val rdd2 = rddRatings.map(x => (x._2, x._3)).partitionBy(p)\n",
    "\n",
    "// id, title, rating\n",
    "\n",
    "val joined = rdd1.join(rdd2)\n",
    "\n",
    "joined.map(x => ((x._1, x._2._1), x._2._2))\n",
    "    .aggregateByKey((0.0,0.0))((a,v)=>(a._1+v,a._2+1), (a1,a2)=>(a1._1+a2._1,a1._2+a2._2))\n",
    "    .map({case(k,v)=>(k,Math.round(v._1*100/v._2)/100.0)})\n",
    "\n",
    "// 2. aggregate and then join\n",
    "\n",
    "val rdd3 = rddMovies.map(x => (x._1, x._2)).partitionBy(p)\n",
    "val rdd4 = rddRatings.map(x => (x._2, x._3))\n",
    "    .aggregateByKey((0.0,0.0))((a,v)=>(a._1+v,a._2+1), (a1,a2)=>(a1._1+a2._1,a1._2+a2._2))\n",
    "    .map({case(k,v)=>(k,Math.round(v._1*100/v._2)/100.0)})\n",
    "    .partitionBy(p)\n",
    "\n",
    "rdd3.join(rdd4).take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07050d2-4447-4765-814d-2cd0ff1402c1",
   "metadata": {},
   "source": [
    "## 104-3 Genres\n",
    "\n",
    "Make a chart of best-ranked genres, Export the result to a file, then use Power BI to check it.\n",
    "\n",
    "Two possible workflows:\n",
    "\n",
    "1. Pre-aggregation (3 shuffles)\n",
    "\n",
    "  - Aggregate ratings by movieId\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres\n",
    "  \n",
    "2. Join & aggregate (2 shuffles)\n",
    "\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a8f82-2006-49a6-9a99-9de6638df74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val path_output_avgRatPerGenre = \"s3a://\"+bucketname+\"/spark/avgRatPerGenre\"\n",
    "\n",
    "for ((k,v) <- sc.getPersistentRDDs) {\n",
    "  v.unpersist()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561f111-ba3f-4d78-a824-38377ace82b1",
   "metadata": {},
   "source": [
    "## 104-4 Tags\n",
    "\n",
    "What can you find out about tags?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
